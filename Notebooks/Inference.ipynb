{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87355340-a736-4f62-affc-be0bc40c9ff7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/d3v/anaconda3/envs/wysa/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/d3v/anaconda3/envs/wysa/lib/python3.9/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import Dataset, DatasetDict , load_from_disk\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pd.set_option('display.max_colwidth', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a675ee8-3608-44e9-832b-0432f0f26538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskModel(nn.Module):\n",
    "    def __init__(self, model_name, num_product_labels, num_emotion_labels):\n",
    "        super(MultitaskModel, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.dropout = nn.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        \n",
    "        self.product_classifier = nn.Linear(hidden_size, num_product_labels)\n",
    "        self.emotion_classifier = nn.Linear(hidden_size, num_emotion_labels)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        labels=None,  # labels is a tensor of shape (batch_size, 2)\n",
    "    ):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output  # [CLS] token representation\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        product_logits = self.product_classifier(pooled_output)\n",
    "        emotion_logits = self.emotion_classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            product_labels = labels[:, 0]\n",
    "            emotion_labels = labels[:, 1]\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            product_loss = loss_fct(product_logits, product_labels)\n",
    "            emotion_loss = loss_fct(emotion_logits, emotion_labels)\n",
    "            loss = product_loss + emotion_loss  # Combine losses\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': (product_logits, emotion_logits)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "041142f3-eb4b-40ee-83f3-2d1b0bf583b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_encoder = joblib.load('product_encoder.joblib')\n",
    "emotion_encoder = joblib.load('emotion_encoder.joblib')\n",
    "num_product_labels, num_emotion_labels = len(product_encoder.classes_) , len(emotion_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a42d41-f14d-499e-9b6e-51ccabd9010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultitaskModel(\n",
    "    model_name='bert-base-uncased', \n",
    "    num_product_labels=num_product_labels,\n",
    "    num_emotion_labels=num_emotion_labels,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15561df3-2184-4082-af96-536348edd5ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6211/2583355429.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('MODEL_04/pytorch_model.bin', map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultitaskModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (product_classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       "  (emotion_classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('MODEL_04/pytorch_model.bin', map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5fa3cb1-a506-4ac6-8aa4-1914faf697f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('MODEL_04/')\n",
    "\n",
    "def predict_text(texts):\n",
    "    emotion_predictions = []\n",
    "    product_predictions = []\n",
    "\n",
    "    for text in texts:\n",
    "        # Tokenize the raw text\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to model device\n",
    "\n",
    "        # Remove token_type_ids if not required by the model\n",
    "        if 'token_type_ids' in inputs and 'token_type_ids' not in model.forward.__code__.co_varnames:\n",
    "            del inputs['token_type_ids']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "\n",
    "            if isinstance(outputs['logits'], tuple):\n",
    "                product_logits = outputs['logits'][0]\n",
    "                emotion_logits = outputs['logits'][1]\n",
    "            else:\n",
    "                # If it's a single tensor, slice it based on the number of classes\n",
    "                product_logits = outputs['logits'][:, len(product_encoder.classes_):]\n",
    "                emotion_logits = outputs['logits'][:, :len(emotion_encoder.classes_)]\n",
    "\n",
    "            emotion_pred_index = torch.argmax(emotion_logits, dim=1).item()\n",
    "            product_pred_index = torch.argmax(product_logits, dim=1).item()\n",
    "\n",
    "            # Map indices to class names\n",
    "            emotion_pred_class = emotion_encoder.inverse_transform([emotion_pred_index])[0]\n",
    "            product_pred_class = product_encoder.inverse_transform([product_pred_index])[0]\n",
    "\n",
    "        emotion_predictions.append(emotion_pred_class)\n",
    "        product_predictions.append(product_pred_class)\n",
    "\n",
    "    return [{\"emotion_prediction\": e, \"product_prediction\": p} for e, p in zip(emotion_predictions, product_predictions)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9001d7b9-f29a-4b25-be64-7f32bdb85cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'emotion_prediction': 'No emotion toward brand or product', 'product_prediction': 'No Product'}, {'emotion_prediction': 'Positive emotion', 'product_prediction': 'iPad or iPhone App'}]\n"
     ]
    }
   ],
   "source": [
    "raw_texts = [\"Sample text 1\", \"I just love the way IOS animate the new message app\"] \n",
    "predictions = predict_text(raw_texts)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12b1f7-75ad-46d4-88e8-566b4cdeef33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.9-wysa)",
   "language": "python",
   "name": "wysa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
